[project]
name = "ssuextract"
version = "0.9.0"
description = "SSU extraction tools using Nextflow pipeline"
channels = ["conda-forge", "bioconda"]
platforms = ["linux-64", "osx-64", "osx-arm64"]

[dependencies]
# Core tools
python = ">=3.8"
nextflow = "*"
wget = "*"               # for database download

# Bioinformatics tools
infernal = "*"           # provides cmsearch
blast = "*"              # provides blastn

# Python packages
pandas = "*"
biopython = "*"
numpy = "*"

[tasks]
# Download database if not already present
download-db = { cmd = "bash -c 'if [ ! -f resources/database/silva-138-1_pr2-4-12.fasta ]; then mkdir -p resources/database && wget -r -np -nH --cut-dirs=3 -P resources/database/ https://portal.nersc.gov/cfs/nelli/ssuextract_db/; else echo \"Database already exists, skipping download\"; fi'", description = "Download database files if not present" }

# Setup: install dependencies and download database
setup = { depends-on = ["download-db"], description = "Complete setup including database download" }

# Run the full pipeline
run = "nextflow run main.nf"

# Clean outputs
clean = "nextflow clean -f"

# Clean results directory (use with caution)
clean-results = { cmd = "rm -rf results/ work/", description = "Remove all results and work directories" }

# Dry run to see what will be executed
dryrun = "nextflow run main.nf -preview"

# Generate pipeline visualization
dag = "nextflow run main.nf -with-dag pipeline.svg"

[environments]
dev = ["dev"]

[feature.dev.dependencies]
# Development dependencies
graphviz = "*"           # for DAG visualization

[feature.dev.tasks]
# Run with detailed output
run-verbose = "nextflow run main.nf -with-trace -with-timeline -with-report"

# Create pipeline report
report = "nextflow run main.nf -with-report report.html"